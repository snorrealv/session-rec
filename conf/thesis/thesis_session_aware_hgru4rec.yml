---
type: opt # single|window, maybe add opt
key: hgru4rec #added to the csv names
evaluation: evaluation_user_based #evaluation|evaluation_last|evaluation_multiple
data:
  name: thesis #added in the end of the csv names
  folder: data/thesis/prepared/
  prefix: thesis_240k
  type: hdf # hdf|csv(default)
#  slices: 5 #only window
#  skip: [0,3] #only window
  opts:
    { session_key : sessionId,
    item_key : categoryId,
    time_key : timestamp,
    user_key : profileId }

results:
  folder: results/session-aware/tv2/hgru4rec/

metrics:
- class: accuracy_multiple.Precision
  length: [5,10,15,20]
- class: accuracy_multiple.Recall
  length: [5,10,15,20]
- class: accuracy_multiple.MAP
  length: [5,10,15,20]
- class: accuracy.HitRate
  length: [5,10,15,20]
- class: accuracy.MRR
  length: [5,10,15,20]

optimize:
  class: accuracy.MRR
  length: [20]
  iterations: 10 #optional

algorithms:
- class: hgru4rec.hgru4rec.HGRU4Rec
  params: {session_layers: 100, user_layers: 100, loss: 'top1'} # small network, the TOP1 loss always outperformed other ranking losses, so we consider only it
  params_opt:
    final_act: ['linear', 'relu', 'tanh'] # None means default (tanh if the loss is brp or top1; softmax for cross-entropy) # cross-entropy is only affected by 'tanh' where the softmax layers is proceeded by a tanh nonlinearity (default: None)
    dropout_p_hidden_usr: {from: 0.0, to: 0.9, in: 10, type: float}
    dropout_p_hidden_ses: {from: 0.0, to: 0.9, in: 10, type: float}
    dropout_p_init: {from: 0.0, to: 0.9, in: 10, type: float}
    momentum: {from: 0.0, to: 0.9, in: 10, type: float32}
    learning_rate: [ {from: 0.1, to: 0.01, in: 10, type: float32}, {from: 0.5, to: 0.1, in: 5, type: float32} ]
    user_propagation_mode: ['init', 'all']
  key: hgru4rec